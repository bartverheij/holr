\@doanenote {1}
macro:->On
the
conviction
rate
in
US
federal
courts,
see
the
statistical
reports
of
the
Offices
of
the
United
States
Attorneys,
available
at
\url
{www.justice.gov/usao/resources/annual-statistical-reports}.
Most
of
these
convictions
are
guilty
pleas,
not
convictions
after
trial.
On
Japan's
conviction
rate,
see
\textit
{White
Paper
on
Crime
2014},
Part
2,
Chapter
3,
Section
1,
available
at
\url
{hakusyo1.moj.go.jp/en/63/nfm/mokuji.html}.
\@endanenote 
\@doanenote {2}
macro:->On
the
UK
conviction
rate,
see
\textit
{Criminal
Justice
Statistics--March
2014},
available
at
\url
{www.gov.uk/government/statistics}.
As
in
the
US
case,
the
rate
include
mostly
guilty
pleas.
For
the
Netherlands,
see
CBS,
the
Dutch
central
bureau
of
statistics,
publishing
its
data
at
\url
{www.cbs.nl}.
\@endanenote 
\@doanenote {3}
macro:->See
\url
{www.fbi.gov/services/laboratory/biometric-analysis/codis}.
\@endanenote 
\@doanenote {4}
macro:->See
\url
{www.cstl.nist.gov/strbase/str\_CSF1PO.htm}.
\@endanenote 
\@doanenote {5}
macro:->At
a
rate
of
a
dozen
or
more
twin
births
per
1000
live
births,
identical
twins
are
not
that
rare.
Source
\url
{en.wikipedia.org/wiki/Twin\#Statistics}.
\@endanenote 
\@doanenote {6}
macro:->Bayes'
theorem
can
be
derived
using
the
definition
of
conditional
probability.
We
have
$\Pr
(E|H)
=
\Pr
(H\land
E)/\Pr
(H)$.
Here
we
use
logical
conjunction
$\land
$
to
write
the
combined
event
$H$
and
$E$.
Hence,
$\Pr
(H\land
E)=\Pr
(E|H)\cdot
\Pr
(H)$.
It
follows
that
$\Pr
(H|E)
=
\Pr
(H
\land
E)/\Pr
(E)
=
\Pr
(E|H)\cdot
\Pr
(H)/\Pr
(E)$,
proving
Bayes'
theorem.

\@endanenote 
\@doanenote {7}
macro:->The
language
of
prior
and
posterior
probability
is
standard
in
the
legal
literature,
but
is
misleading.
The
prior
and
posterior
probabilities
are
not
temporally
ordered.
The
former
is
$\Pr
(H)$
and
the
latter
is
$\Pr
(H
|
E)$.
Such
probability
assignments
exist
\textit
{at
the
same
time}
and
their
values
are
determined
by
Bayes'
theorem.
The
language
of
prior
and
posterior
probabilities
make
sense
in
the
context
of
\textit
{Bayesian
conditioning},
that
is,
the
claim
that
if
one
begins
with
prior
probability
assignment
$\Pr
_0$
about
$H$,
$\Pr
_0(H)$,
and
one
acquires
new
evidence
$E$
about
$H$,
then
rationality
requires
that
one
transform
one's
prior
to
generate
posterior
probability
assignment
$P_1$
about
$H$
by
conditionalizing
on
$E$,
that
is,
$\Pr
_1(H)
=
\Pr
_0(H
|
E)$,
where
$\Pr
_0(H
|
E
)$
is
determined
using
Bayes'
theorem.
\label
{conditioning}
See
\cite
{bovensEtAl2003}.
\@endanenote 
\@doanenote {8}
macro:->To
see
why,
recall
that
\[
\frac
{\Pr
(H|E)}{\Pr
(\neg
H
|
E)}
=
\frac
{\Pr
(E
|
H)}{\Pr
(E|
\neg
H)}\cdot
\frac
{\Pr
(H)}{\Pr
(\neg
H)},\]
which
implies
\[\frac
{\Pr
(E|H)}{\Pr
(E|\neg
H)}>1
\text
{
iff
}
\frac
{\Pr
(H|E)}{\Pr
(\neg
H
|
E)}
>
\frac
{\Pr
(H)}{\Pr
(\neg
H)}.\]
For
one
direction,
if
$\Pr
(H|E)>
P(H)$,
then
$1-
P(H|E)<
1-
P(H)$.
This
means
that
$\frac
{\Pr
(H|E)}{1-
P(H
|
E)}
>
\frac
{\Pr
(H)}{1-
P(H)}$,
and
thus
$\frac
{\Pr
(H|E)}{\Pr
(\neg
H
|
E)}
>
\frac
{\Pr
(H)}{\Pr
(\neg
H)}$.
So,
by
the
equivalence
above,
$\frac
{\Pr
(E|H)}{\Pr
(E|\neg
H)}>1$.
For
the
other
direction,
if
$\frac
{\Pr
(E|H)}{\Pr
(E|\neg
H)}>1$,
then
$\frac
{\Pr
(H|E)}{\Pr
(\neg
H
|
E)}
>
\frac
{\Pr
(H)}{\Pr
(\neg
H)}$,
again
by
the
equivalence
above.
The
latter
is
the
same
as
$\frac
{\Pr
(H|E)}{1-
P(H
|
E)}
>
\frac
{\Pr
(H)}{1-
P(H)}$.
To
establish
$\Pr
(H|E)>
P(H)$,
suppose
for
contradiction
that
$\Pr
(H|E)
\leq
P(H)$,
which
implies
$1-
P(H|E)
\geq
1-
P(H)$.
This
means
that
$\frac
{\Pr
(H|E)}{1-
P(H
|
E)}
\leq
\frac
{\Pr
(H)}{1-
P(H)}$.
This
contradicts
$\frac
{\Pr
(H|E)}{1-
P(H
|
E)}
>
\frac
{\Pr
(H)}{1-
P(H)}$,
and
thus
$\Pr
(H|E)>
P(H)$.
\@endanenote 
\@doanenote {9}
macro:->On
the
distinction
between
priors
and
posteriors,
see
note
\ref
{conditioning}.
\@endanenote 
\@doanenote {10}
macro:->To
derive
the
likelihood
ratio
formula,
one
first
applies
Bayes'
theorem
to
both
$H$
and
$\neg
H$.
We
get
$\Pr
(H|E)
=
\Pr
(E|H)\cdot
\Pr
(H)/\Pr
(E)$
and
$\Pr
(\neg
H|E)
=
\Pr
(E|\neg
H)\cdot
\Pr
(\neg
H)/\Pr
(E)$.
Using
these,
we
find:
\par
\begin
{equation*}
\frac
{\Pr
(H|E)}{\Pr
(\neg
H|E)}
=
\frac
{\Pr
(E|H)\cdot
\Pr
(H)/\Pr
(E)}
{\Pr
(E|\neg
H)\cdot
\Pr
(\neg
H)/\Pr
(E)}
=
\frac
{\Pr
(E|H)\cdot
\Pr
(H)}
{\Pr
(E|\neg
H)\cdot
\Pr
(\neg
H)},
\end
{equation*}
\par
\noindent
proving
the
likelihood
ratio
formula.
\@endanenote 
\@doanenote {11}
macro:->$\Pr
(H|E)=\frac
{\Pr
(H|E)}{\Pr
(H|E)+\Pr
(\neg
H|E)}=\frac
{\frac
{\Pr
(H|E)}{\Pr
(\neg
H|E)}}{\frac
{\Pr
(H|E)+\Pr
(\neg
H|E)}{\Pr
(\neg
H|E)}}=\frac
{\frac
{\Pr
(H|E)}{\Pr
(\neg
H|E)}}{\frac
{\Pr
(H|E)}{\Pr
(\neg
H|E)}+1}$.
\@endanenote 
